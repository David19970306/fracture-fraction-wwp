@inproceedings{Miao2019,
   abstract = {In clinical diagnosis, automatic fracture detection can reduce misdiagnosis which caused by fatigue and inexperience of radiologists, and provide support for reducing patient suffering and preventing disease progression. This paper proposes a SK-DenseNet model to detect femur fracture based on DenseNet network. It uses SK module to adjust the size of receptive fields adaptively, adopts Focal loss function to update parameter, and uses Grad-CAM method to visualize the femoral detection results. It can improve the interpretability of the fracture detection model. This paper used the femoral dataset to verify the performance of the mode. Our model achieves an accuracy of 0.9117, with the kappa coefficient is 0.8228. The experimental results show that the performance of the proposed model is better than the traditional deep learning model.},
   author = {Yu Miao and Peng Fei Zhao and Xiong Feng Tang and Yu Qin Li and Li Yuan Zhang and Wei Li Shi and Ke Zhang and Hua Min Yang and Jian Hua Liu},
   doi = {10.1145/3358331.3358402},
   isbn = {9781450372022},
   journal = {ACM International Conference Proceeding Series},
   keywords = {CAD,Deep learning,Femoral fracture,SK-DenseNet},
   month = {10},
   publisher = {Association for Computing Machinery},
   title = {A method for detecting femur fracture based on SK-Densenet},
   year = {2019},
}
@article{Gan2019,
   abstract = {Background and purpose — Artificial intelligence has rapidly become a powerful method in image analysis with the use of convolutional neural networks (CNNs). We assessed the ability of a CNN, with a fast object detection algorithm previously identifying the regions of interest, to detect distal radius fractures (DRFs) on anterior–posterior (AP) wrist radiographs. Patients and methods — 2,340 AP wrist radiographs from 2,340 patients were enrolled in this study. We trained the CNN to analyze wrist radiographs in the dataset. Feasibility of the object detection algorithm was evaluated by intersection of the union (IOU). The diagnostic performance of the network was measured by area under the receiver operating characteristics curve (AUC), accuracy, sensitivity, specificity, and Youden Index; the results were compared with those of medical professional groups. Results — The object detection model achieved a high average IOU, and none of the IOUs had a value less than 0.5. The AUC of the CNN for this test was 0.96. The network had better performance in distinguishing images with DRFs from normal images compared with a group of radiologists in terms of the accuracy, sensitivity, specificity, and Youden Index. The network presented a similar diagnostic performance to that of the orthopedists in terms of these variables. Interpretation — The network exhibited a diagnostic ability similar to that of the orthopedists and a performance superior to that of the radiologists in distinguishing AP wrist radiographs with DRFs from normal images under limited conditions. Further studies are required to determine the feasibility of applying our method as an auxiliary in clinical practice under extended conditions.},
   author = {Kaifeng Gan and Dingli Xu and Yimu Lin and Yandong Shen and Ting Zhang and Keqi Hu and Ke Zhou and Mingguang Bi and Lingxiao Pan and Wei Wu and Yunpeng Liu},
   doi = {10.1080/17453674.2019.1600125},
   issn = {17453682},
   issue = {4},
   journal = {Acta Orthopaedica},
   month = {7},
   pages = {394-400},
   publisher = {Taylor and Francis Ltd},
   title = {Artificial intelligence detection of distal radius fractures: a comparison between the convolutional neural network and professional assessments},
   volume = {90},
   year = {2019},
}
@article{Spampinato2017,
   abstract = {Skeletal bone age assessment is a common clinical practice to investigate endocrinology, genetic and growth disorders in children. It is generally performed by radiological examination of the left hand by using either the Greulich and Pyle (G&P) method or the Tanner–Whitehouse (TW) one. However, both clinical procedures show several limitations, from the examination effort of radiologists to (most importantly) significant intra- and inter-operator variability. To address these problems, several automated approaches (especially relying on the TW method) have been proposed; nevertheless, none of them has been proved able to generalize to different races, age ranges and genders. In this paper, we propose and test several deep learning approaches to assess skeletal bone age automatically; the results showed an average discrepancy between manual and automatic evaluation of about 0.8 years, which is state-of-the-art performance. Furthermore, this is the first automated skeletal bone age assessment work tested on a public dataset and for all age ranges, races and genders, for which the source code is available, thus representing an exhaustive baseline for future research in the field. Beside the specific application scenario, this paper aims at providing answers to more general questions about deep learning on medical images: from the comparison between deep-learned features and manually-crafted ones, to the usage of deep-learning methods trained on general imagery for medical problems, to how to train a CNN with few images.},
   author = {C. Spampinato and S. Palazzo and D. Giordano and M. Aldinucci and R. Leonardi},
   doi = {10.1016/j.media.2016.10.010},
   issn = {13618423},
   journal = {Medical Image Analysis},
   keywords = {Convolutional neural networks,Deep learning for medical images,Greulich and Pyle,Tanner–Whitehouse},
   month = {2},
   pages = {41-51},
   publisher = {Elsevier B.V.},
   title = {Deep learning for automated skeletal bone age assessment in X-ray images},
   volume = {36},
   year = {2017},
}
@article{Yahalomi2018,
   abstract = {Distal radius fractures are the most common fractures of the upper extremity in humans. As such, they account for a significant portion of the injuries that present to emergency rooms and clinics throughout the world. We trained a Faster R-CNN, a machine vision neural network for object detection, to identify and locate distal radius fractures in anteroposterior X-ray images. We achieved an accuracy of 96\% in identifying fractures and mean Average Precision, mAP, of 0.866. This is significantly more accurate than the detection achieved by physicians and radiologists. These results were obtained by training the deep learning network with only 38 original images of anteroposterior hands X-ray images with fractures. This opens the possibility to detect with this type of neural network rare diseases or rare symptoms of common diseases , where only a small set of diagnosed X-ray images could be collected for each disease.},
   author = {Erez Yahalomi and Michael Chernofsky and Michael Werman},
   month = {12},
   title = {Detection of distal radius fractures trained by a small set of X-ray images and Faster R-CNN},
   url = {http://arxiv.org/abs/1812.09025},
   year = {2018},
}
@inproceedings{Lee2015,
   abstract = {Radiographic image assessment is the most common method used to measure physical maturity and diagnose growth disorders, hereditary diseases and rheumatoid arthritis, with hand radiography being one of the most frequently used techniques due to its simplicity and minimal exposure to radiation. Finger joints are considered as especially important factors in hand skeleton examination. Although several automation methods for finger joint detection have been proposed, low accuracy and reliability are hindering full-scale adoption into clinical fields. In this paper, we propose FingerNet, a novel approach for the detection of all finger joints from hand radiograph images based on convolutional neural networks, which requires little user intervention. The system achieved 98.02% average detection accuracy for 130 test data sets containing over 1,950 joints. Further analysis was performed to verify the system robustness against factors such as epiphysis and metaphysis in different age groups.},
   author = {Sungmin Lee and Minsuk Choi and Hyun Soo Choi and Moon Seok Park and Sungroh Yoon},
   doi = {10.1109/BioCAS.2015.7348440},
   isbn = {9781479972333},
   journal = {IEEE Biomedical Circuits and Systems Conference: Engineering for Healthy Minds and Able Bodies, BioCAS 2015 - Proceedings},
   month = {12},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {FingerNet: Deep learning-based robust finger joint detection from radiographs},
   year = {2015},
}
@article{Lindsey2018,
   abstract = {Suspected fractures are among the most common reasons for patients to visit emergency departments (EDs), and X-ray imaging is the primary diagnostic tool used by clinicians to assess patients for fractures. Missing a fracture in a radiograph often has severe consequences for patients, resulting in delayed treatment and poor recovery of function. Nevertheless, radiographs in emergency settings are often read out of necessity by emergency medicine clinicians who lack subspecialized expertise in orthopedics, and misdiagnosed fractures account for upward of four of every five reported diagnostic errors in certain EDs. In this work, we developed a deep neural network to detect and localize fractures in radiographs. We trained it to accurately emulate the expertise of 18 senior subspecialized orthopedic surgeons by having them annotate 135,409 radiographs. We then ran a controlled experiment with emergency medicine clinicians to evaluate their ability to detect fractures in wrist radiographs with and without the assistance of the deep learning model. The average clinician's sensitivity was 80.8% (95% CI, 76.7-84.1%) unaided and 91.5% (95% CI, 89.3-92.9%) aided, and specificity was 87.5% (95 CI, 85.3-89.5%) unaided and 93.9% (95% CI, 92.9-94.9%) aided. The average clinician experienced a relative reduction in misinterpretation rate of 47.0% (95% CI, 37.4-53.9%). The significant improvements in diagnostic accuracy that we observed in this study show that deep learning methods are a mechanism by which senior medical specialists can deliver their expertise to generalists on the front lines of medicine, thereby providing substantial improvements to patient care.},
   author = {Robert Lindsey and Aaron Daluiski and Sumit Chopra and Alexander Lachapelle and Michael Mozer and Serge Sicular and Douglas Hanel and Michael Gardner and Anurag Gupta and Robert Hotchkiss and Hollis Potter},
   doi = {10.1073/pnas.1806905115},
   issn = {10916490},
   issue = {45},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {CAD,Deep learning,Fractures,Radiology,X-ray},
   month = {11},
   pages = {11591-11596},
   publisher = {National Academy of Sciences},
   title = {Deep neural network improves fracture detection by clinicians},
   volume = {115},
   year = {2018},
}
@report{,
   abstract = {Computer aided diagnosis is a hot research field. Systems with the ability to provide a highly accurate diagnosis using little resources are highly desirable. One type of such systems depend on medical images to provide instantaneous diagnosis based on some discriminative features extracted from the images after processing them for noise removal and enhancement. In this paper, we propose a system to automatically detect fractures in hand bones using x-ray images. To the best of our knowledge, this problemhave never been addressed before. For a first attempt to tackle such a difficult problem, our system performed incredibly good with a 91.8% accuracy.},
   author = {Mahmoud Al-Ayyoub and Ismail Hmeidi and Haya Rababah Jordan},
   journal = {Journal of Multimedia Processing and Technologies},
   keywords = {Fractures Diagnosis,Medical Images,Noise Removal,X-Ray Images},
   title = {Detecting Hand Bone Fractures in X-Ray Images},
   volume = {4},
   year = {2013},
}
@article{Rajpurkar2017,
   abstract = {We introduce MURA, a large dataset of musculoskeletal radiographs containing 40,561 images from 14,863 studies, where each study is manually labeled by radiologists as either normal or abnormal. To evaluate models robustly and to get an estimate of radiologist performance, we collect additional labels from six board-certified Stanford radiologists on the test set, consisting of 207 musculoskeletal studies. On this test set, the majority vote of a group of three radiologists serves as gold standard. We train a 169-layer DenseNet baseline model to detect and localize abnormalities. Our model achieves an AUROC of 0.929, with an operating point of 0.815 sensitivity and 0.887 specificity. We compare our model and radiologists on the Cohen's kappa statistic, which expresses the agreement of our model and of each radiologist with the gold standard. Model performance is comparable to the best radiologist performance in detecting abnormalities on finger and wrist studies. However, model performance is lower than best radiologist performance in detecting abnormalities on elbow, forearm, hand, humerus, and shoulder studies. We believe that the task is a good challenge for future research. To encourage advances, we have made our dataset freely available at https://stanfordmlgroup.github.io/competitions/mura .},
   author = {Pranav Rajpurkar and Jeremy Irvin and Aarti Bagul and Daisy Ding and Tony Duan and Hershel Mehta and Brandon Yang and Kaylie Zhu and Dillon Laird and Robyn L. Ball and Curtis Langlotz and Katie Shpanskaya and Matthew P. Lungren and Andrew Y. Ng},
   month = {12},
   title = {MURA: Large Dataset for Abnormality Detection in Musculoskeletal Radiographs},
   url = {http://arxiv.org/abs/1712.06957},
   year = {2017},
}
@article{Kim2018,
   abstract = {Aim: To identify the extent to which transfer learning from deep convolutional neural networks (CNNs), pre-trained on non-medical images, can be used for automated fracture detection on plain radiographs. Materials and methods: The top layer of the Inception v3 network was re-trained using lateral wrist radiographs to produce a model for the classification of new studies as either “fracture” or “no fracture”. The model was trained on a total of 11,112 images, after an eightfold data augmentation technique, from an initial set of 1,389 radiographs (695 “fracture” and 694 “no fracture”). The training data set was split 80:10:10 into training, validation, and test groups, respectively. An additional 100 wrist radiographs, comprising 50 “fracture” and 50 “no fracture” images, were used for final testing and statistical analysis. Results: The area under the receiver operator characteristic curve (AUC) for this test was 0.954. Setting the diagnostic cut-off at a threshold designed to maximise both sensitivity and specificity resulted in values of 0.9 and 0.88, respectively. Conclusion: The AUC scores for this test were comparable to state-of-the-art providing proof of concept for transfer learning from CNNs in fracture detection on plain radiographs. This was achieved using only a moderate sample size. This technique is largely transferable, and therefore, has many potential applications in medical imaging, which may lead to significant improvements in workflow productivity and in clinical risk reduction.},
   author = {D. H. Kim and T. MacKinnon},
   doi = {10.1016/j.crad.2017.11.015},
   issn = {1365229X},
   issue = {5},
   journal = {Clinical Radiology},
   month = {5},
   pages = {439-445},
   pmid = {29269036},
   publisher = {W.B. Saunders Ltd},
   title = {Artificial intelligence in fracture detection: transfer learning from deep convolutional neural networks},
   volume = {73},
   year = {2018},
}
@generic{Langerhuizen2019,
   abstract = {BackgroundArtificial-intelligence algorithms derive rules and patterns from large amounts of data to calculate the probabilities of various outcomes using new sets of similar data. In medicine, artificial intelligence (AI) has been applied primarily to image-recognition diagnostic tasks and evaluating the probabilities of particular outcomes after treatment. However, the performance and limitations of AI in the automated detection and classification of fractures has not been examined comprehensively.Question/purposesIn this systematic review, we asked (1) What is the proportion of correctly detected or classified fractures and the area under the receiving operating characteristic (AUC) curve of AI fracture detection and classification models? (2) What is the performance of AI in this setting compared with the performance of human examiners?MethodsThe PubMed, Embase, and Cochrane databases were systematically searched from the start of each respective database until September 6, 2018, using terms related to "fracture", "artificial intelligence", and "detection, prediction, or evaluation." Of 1221 identified studies, we retained 10 studies: eight studies involved fracture detection (ankle, hand, hip, spine, wrist, and ulna), one addressed fracture classification (diaphyseal femur), and one addressed both fracture detection and classification (proximal humerus). We registered the review before data collection (PROSPERO: CRD42018110167) and used the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA). We reported the range of the accuracy and AUC for the performance of the predicted fracture detection and/or classification task. An AUC of 1.0 would indicate perfect prediction, whereas 0.5 would indicate a prediction is no better than a flip-of-a-coin. We conducted quality assessment using a seven-item checklist based on a modified methodologic index for nonrandomized studies instrument (MINORS).ResultsFor fracture detection, the AUC in five studies reflected near perfect prediction (range, 0.95-1.0), and the accuracy in seven studies ranged from 83% to 98%. For fracture classification, the AUC was 0.94 in one study, and the accuracy in two studies ranged from 77% to 90%. In two studies AI outperformed human examiners for detecting and classifying hip and proximal humerus fractures, and one study showed equivalent performance for detecting wrist, hand and ankle fractures.ConclusionsPreliminary experience with fracture detection and classification using AI shows promising performance. AI may enhance processing and communicating probabilistic tasks in medicine, including orthopaedic surgery. At present, inadequate reference standard assignments to train and test AI is the biggest hurdle before integration into clinical workflow. The next step will be to apply AI to more challenging diagnostic and therapeutic scenarios when there is absence of certitude. Future studies should also seek to address legal regulation and better determine feasibility of implementation in clinical practice.Level of EvidenceLevel II, diagnostic study.},
   author = {David W.G. Langerhuizen and Stein J. Janssen and Wouter H. Mallee and Michel P.J. Van Den Bekerom and David Ring and Gino M.M.J. Kerkhoffs and Ruurd L. Jaarsma and Job N. Doornberg},
   doi = {10.1097/CORR.0000000000000848},
   issn = {15281132},
   issue = {11},
   journal = {Clinical Orthopaedics and Related Research},
   month = {11},
   pages = {2482-2491},
   pmid = {31283727},
   publisher = {Lippincott Williams and Wilkins},
   title = {What Are the Applications and Limitations of Artificial Intelligence for Fracture Detection and Classification in Orthopaedic Trauma Imaging? A Systematic Review},
   volume = {477},
   year = {2019},
}
