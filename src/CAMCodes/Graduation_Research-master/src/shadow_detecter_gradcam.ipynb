{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 300, 300, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1512)              125412840 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 3026      \n",
      "=================================================================\n",
      "Total params: 126,588,122\n",
      "Trainable params: 126,588,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "1\n",
      "[[0.01172949 0.9882705 ]]\n",
      "Tensor(\"max_pooling2d_3/MaxPool:0\", shape=(?, 37, 37, 128), dtype=float32)\n",
      "~~~~~~\n",
      "Tensor(\"conv2d_1_input:0\", shape=(?, 300, 300, 3), dtype=float32)\n",
      "Tensor(\"gradients_1/conv2d_1/convolution_grad/Conv2DBackpropInput:0\", shape=(?, 300, 300, 3), dtype=float32)\n",
      "[array([[[[-0.00551885, -0.00241277, -0.00279888],\n",
      "         [ 0.03090677,  0.01078927,  0.00205998],\n",
      "         [ 0.06801052,  0.00359706, -0.00630279],\n",
      "         ...,\n",
      "         [ 0.09753437,  0.03188805,  0.01439111],\n",
      "         [ 0.04966968,  0.09651997, -0.01875258],\n",
      "         [ 0.06219874, -0.00448812,  0.00196473]],\n",
      "\n",
      "        [[ 0.02142693,  0.01106045, -0.00348052],\n",
      "         [ 0.0519206 ,  0.02787317, -0.01726383],\n",
      "         [ 0.07585229,  0.01731589, -0.0411886 ],\n",
      "         ...,\n",
      "         [ 0.00392832, -0.0120981 , -0.14333296],\n",
      "         [ 0.06878324,  0.06057605, -0.05826453],\n",
      "         [ 0.00644405,  0.06143763, -0.03343344]],\n",
      "\n",
      "        [[ 0.04617599, -0.00789368, -0.0180492 ],\n",
      "         [-0.00302109,  0.00528305, -0.04666634],\n",
      "         [ 0.06778357,  0.04508452, -0.0298681 ],\n",
      "         ...,\n",
      "         [ 0.28230238,  0.02908266, -0.1333255 ],\n",
      "         [ 0.11780711,  0.04949298, -0.11909002],\n",
      "         [ 0.04768343,  0.01684565, -0.07245691]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.06661272,  0.02191716, -0.01856169],\n",
      "         [ 0.07811855,  0.06212316, -0.05745384],\n",
      "         [ 0.11953726, -0.00644837, -0.09785746],\n",
      "         ...,\n",
      "         [ 0.10485248,  0.04777057, -0.05167995],\n",
      "         [ 0.00987972,  0.0368963 , -0.00771387],\n",
      "         [ 0.0340732 , -0.00958911, -0.02131603]],\n",
      "\n",
      "        [[ 0.05702938, -0.00568399, -0.01930701],\n",
      "         [ 0.09437416,  0.0175243 , -0.05484319],\n",
      "         [ 0.07315894, -0.00542635, -0.04182543],\n",
      "         ...,\n",
      "         [ 0.04939219,  0.01382338, -0.01627675],\n",
      "         [ 0.01754297,  0.04799728, -0.01145936],\n",
      "         [-0.00123151, -0.00102139, -0.01387003]],\n",
      "\n",
      "        [[ 0.03102111,  0.01025152,  0.01247266],\n",
      "         [ 0.03263798, -0.00991952, -0.03530719],\n",
      "         [ 0.00796107,  0.05418885, -0.00800038],\n",
      "         ...,\n",
      "         [ 0.01579016,  0.0140651 ,  0.00234031],\n",
      "         [ 0.00169694,  0.02448322, -0.00417805],\n",
      "         [-0.00064591,  0.01183516,  0.001542  ]]]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7effce621470>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seimei/usr/bin/virtualenv/tensorflow-with-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1415, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/seimei/usr/bin/virtualenv/tensorflow-with-gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import cross_validation\n",
    "import keras.callbacks\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "\n",
    "from keras.models import load_model\n",
    "import random as rn\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input \n",
    "#https://stackoverflow.com/questions/47555829/preprocess-input-method-in-keras                                                                                                            \n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "#from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from PIL import ImageFile\n",
    "import math\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras \n",
    "import sys \n",
    "import cv2\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#画像がPILでロードできない問題について\n",
    "# PILは極端に大きな画像など高速にロードできない画像はロードしないで見過ごす仕様になっている故の解決法\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 使用するGPUの割り当てを決定する\n",
    "config = tf.ConfigProto(device_count={'GPU':0 ,'CPU':56})\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "STANDARD_SIZE = (300, 300)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)                              \n",
    "\n",
    "input_shape = (300, 300, 3)\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "num_classes = 2\n",
    "f_log = './logs/object_classificationAB/'\n",
    "f_model = './model/test/'\n",
    "\n",
    "\n",
    "model_filename = 'cnn_model.json'\n",
    "weights_filename = 'cnn_model_weights.hdf5'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def input_data(path_train, path_test):\n",
    "\n",
    "    x = []\n",
    "\n",
    "    with open(path_train, \"r\") as f:\n",
    "        train_path_list = f.readlines()\n",
    "\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    for row in train_path_list:\n",
    "        row = row.split(\" \")\n",
    "        filenames.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "\n",
    "    for f in filenames:\n",
    "        x.append(image.img_to_array(img_to_matrix(f)))\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    #正規化                                                                                                                 \n",
    "    x = (x-np.amin(x))/(np.amax(x)-np.amin(x))\n",
    "\n",
    "    y = np.asarray(labels)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "    '==============================================================='\n",
    "\n",
    "    a = []\n",
    "    \n",
    "    with open(path_test, \"r\") as f:\n",
    "        train_path_list = f.readlines()\n",
    "\n",
    "    filenames1 = []\n",
    "    labels1 = []\n",
    "    for row in train_path_list:\n",
    "        row = row.split(\" \")\n",
    "        filenames1.append(row[0])\n",
    "        labels1.append(int(row[1]))\n",
    "\n",
    "    for f in filenames1:\n",
    "        a.append(image.img_to_array(img_to_matrix(f)))\n",
    "\n",
    "    test_data = np.asarray(a)\n",
    "    # 正規化                                                                                                                \n",
    "  #  test_data /= 255\n",
    "    test_data = (test_data-np.amin(test_data))/(np.amax(test_data)-np.amin(test_data))\n",
    "    test_label = np.asarray(labels1)\n",
    "    test_label = keras.utils.to_categorical(test_label, num_classes)\n",
    "\n",
    "    train_data, valid_data, train_label, valid_label = cross_validation.train_test_split(x, y, test_size=0.3)\n",
    "    test_data, valid1, test_label, valid2 = cross_validation.train_test_split(test_data, test_label, test_size=0.3)\n",
    "    \n",
    "    print(np.shape(train_data))\n",
    "    print(np.shape(train_label))\n",
    "    return train_data, test_data, train_label, test_label, valid_data, valid_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tf_image_translate(images, tx, ty, interpolation=\"NEAREST\"):\n",
    "    # got these parameters from solving the equations for pixel translations\n",
    "    # on https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform\n",
    "    transforms = [1, 0, -tx, 0, 1, -ty]\n",
    "    return tf.contrib.image.transform(images, transforms, interpolation)\n",
    "    \"\"\"\n",
    "    #augmentations\n",
    "    if is_training():\n",
    "        #color augmentations\n",
    "        image = tf.image.random_brightness(image,max_delta=63)\n",
    "        #image = tf.image.random_saturation(image, lower=0.5, upper=1.5, seed=seed2) \n",
    "        #image = tf.image.random_hue(image, max_delta=0.2, seed=seed3)\n",
    "        image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "        \n",
    "        tx = tf.random_normal(shape=[], mean=0.0, stddev=20.0, dtype=tf.float32)#正規分布によるランダム値 \n",
    "        ty = tf.random_normal(shape=[], mean=0.0, stddev=20.0, dtype=tf.float32)\n",
    "        image = tf_image_translate(image, tx=tx, ty=ty)\n",
    "        \n",
    "        degrees = tf.random_normal(shape=[], mean=0.0, stddev=5.0, dtype=tf.float32)\n",
    "        image = tf.contrib.image.rotate(image, degrees*math.pi/180, interpolation=\"BILINEAR\")\n",
    "        \n",
    "        print(type(tf.Session().run(tf.constant([1,2,3]))))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# parse image                                                                                                               \n",
    "def img_to_matrix(filename, verbose=False):\n",
    "    img = Image.open(filename)\n",
    "    if verbose:\n",
    "        print('changing size from %s to %s' % (str(img.size), str(STANDARD_SIZE)))\n",
    "    img = img.resize(STANDARD_SIZE)\n",
    "    imgArray = np.asarray(img)\n",
    "    return imgArray  # imgArray.shape = (167 x 300 x 3)                                                                     \n",
    "\n",
    "\n",
    "    \n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, KTF.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (KTF.sqrt(KTF.mean(KTF.square(x)) + 1e-5))\n",
    "\n",
    "def load_image(path):\n",
    "    img_path = path\n",
    "    img = image.load_img(img_path, target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) *  tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "def compile_saliency_function(input_model, activation_layer):\n",
    "\n",
    "    category_index=1\n",
    "    nb_classes = num_classes\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    s = input_model.layers[-1].output\n",
    "    x1 = Lambda(target_layer, output_shape=target_category_loss_output_shape)(s)\n",
    "    model = keras.models.Model(input_model.layers[0].input, x1)\n",
    "    input_img = model.layers[0].input\n",
    "    print(input_img)\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output =layer_dict[activation_layer].output\n",
    "   #print(layer_output)\n",
    "    max_output = KTF.max(layer_output, axis=3)\n",
    "    saliency = KTF.gradients(KTF.sum(max_output), input_img)[0]\n",
    "    print(saliency)\n",
    "    \n",
    "    return KTF.function([input_img, KTF.learning_phase()], [saliency])\n",
    "\n",
    "\n",
    "      \n",
    "def modify_backprop(model, name):\n",
    "\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:]\n",
    "                      if hasattr(layer, 'activation')]\n",
    "\n",
    "        # replace relu activation\n",
    "        for layer1 in layer_dict:\n",
    "            if layer1.activation == keras.activations.relu:\n",
    "                layer1.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = model\n",
    "    return new_model\n",
    "\n",
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if KTF.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "        \n",
    "def grad_cam(input_model, image, category_index, layer_name):\n",
    "  \n",
    "    nb_classes = num_classes\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    x = input_model.layers[-1].output\n",
    "    x = Lambda(target_layer, output_shape=target_category_loss_output_shape)(x)\n",
    "    model = keras.models.Model(input_model.layers[0].input, x)\n",
    "\n",
    "    conv_output =model.layers[9].output #model.layers[5].output \n",
    "    print(conv_output)\n",
    "    #print(conv_output =  [l for l in input_model.layers if l.name == layer_name][0].output)\n",
    "    \n",
    "    loss = KTF.sum(model.layers[-1].output)\n",
    "    print(\"~~~~~~\")\n",
    "\n",
    "    grads = normalize(KTF.gradients(loss, conv_output)[0])\n",
    "    gradient_function = KTF.function([model.layers[0].input], [conv_output, grads])\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    #多分GAP\n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w* (255*output[:, :, i])\n",
    "\n",
    "    cam = cv2.resize(cam, (300, 300))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    \n",
    "    #Return to BGR [0..255] from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "\n",
    "    cam1 = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam1) + np.float32(255*image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    cv2.imwrite(\"heat.jpg\",cam1)\n",
    "    return np.uint8(cam), heatmap\n",
    "\n",
    "\n",
    "def check_accuracy_rate(model):\n",
    "    path_and_label_and_weather = []\n",
    "    with open(\"./path_and_label_test.txt\",\"r\") as s:\n",
    "            image_urls=s.readlines()\n",
    "    \n",
    "    for i in image_urls:\n",
    "            url_and_label=i.strip(\" \").split(\" \")\n",
    "            image_url = url_and_label[0]\n",
    "            image_label=url_and_label[1]\n",
    "            img = image.load_img(image_url, target_size=(300,300))\n",
    "            img=image.img_to_array(img)\n",
    "            img.astype(\"float32\")\n",
    "            img/=255.0\n",
    "            predictions=model.predict(np.expand_dims(img,axis=0))\n",
    "            predicted_label=np.argmax(predictions)\n",
    "            if int(predicted_label) != int(image_label):\n",
    "                t=image_url.split(\"/\")\n",
    "                count=0\n",
    "                for s in t:\n",
    "                    if s==\"dataset_valid\":\n",
    "                        name=t[count+1]\n",
    "                    count+=1\n",
    "                path_and_label_and_weather.append([image_url,name,predicted_label,int(image_label)])\n",
    "                \n",
    "                with open(\"./doc/shadow/incorrect_test_images.txt\",\"a\") as f:\n",
    "                    f.write(image_url+\"\\n\")\n",
    "\n",
    "            elif int(predicted_label) == int(image_label) :\n",
    "                if (predictions[0,predicted_label] < np.float32(\"0.7\")):\n",
    "                    with open(\"./doc/shadow/corret_test_images.txt\",\"a\") as g:\n",
    "                        g.write(image_url+\"\\n\")\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    df = pd.DataFrame(path_and_label_and_weather,columns=[\"path\",\"weater\",\"predicted_label\",\"label\"])\n",
    "    #df=df.set_index(\"weater\")\n",
    "    df.to_csv(\"./doc/shadow/incorrect_test_images.csv\")\n",
    "        \n",
    "\n",
    "# 1次元に引き延ばす(PCAで使用)                                                                                              \n",
    "def flatten_image(img):\n",
    "\n",
    "    s = img.shape[0] * img.shape[1] #* img.shape[2]\n",
    "    img_wide = img.reshape(1, s)\n",
    "    return img_wide[0]\n",
    "\n",
    "\n",
    "def handle_image_with_pca(activations, y_test, channels):\n",
    "    \"\"\"\n",
    "    分類分布をPCAにて取得\n",
    "    \"\"\"\n",
    "    for i in range(2):\n",
    "        images = activations[i,:,:,:]\n",
    "        print(images)\n",
    "        if i == 0:\n",
    "            labels = y_test[:channels]\n",
    "        elif i == 1:\n",
    "            labels = y_test[channels:]\n",
    "        ls = []\n",
    "\n",
    "        for label in labels:\n",
    "\n",
    "            if list(label) == [0,1]:\n",
    "                ls.append(\"non_shadow\")\n",
    "            elif list(label) == [1,0]:\n",
    "                ls.append(\"shadow\")\n",
    "        labels = ls\n",
    "        print(labels)\n",
    "        data = []\n",
    "        for a in range(channels):#for image in images:\n",
    "            img = flatten_image(images[:, :, a])\n",
    "            data.append(img)\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "        is_train = np.random.uniform(0, 1, len(data)) <= 0.7\n",
    "        y = np.where(np.array(labels) == 'non_shadow', 1, 0)\n",
    "        \n",
    "        train_x, train_y = data[is_train], y[is_train]\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        X = pca.fit_transform(data)\n",
    "        if i == 0:\n",
    "            df1 = pd.DataFrame({\"x\": X[:, 0], \"y\": X[:, 1],\n",
    "                               \"label\": np.where(y == 1, 'nonshadow', 'shadow')})\n",
    "        elif i == 1:\n",
    "            df2 = pd.DataFrame({\"x\": X[:, 0], \"y\": X[:, 1],\n",
    "                               \"label\": np.where(y == 1, 'nonshadow', 'shadow')})\n",
    "            df = pd.concat([df1, df2])\n",
    "\n",
    "    colors = ['red','blue']\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for label, color in zip(df['label'].unique(), colors):\n",
    "        mask = df['label'] == label\n",
    "        plt.scatter(df[mask]['x'], df[mask]['y'], c=color, label=label)\n",
    "    sns.set()\n",
    "    plt.xlabel(\"pc1 (Principal Component1)\")  # 全データの分散が最大となる方向                                              \n",
    "    plt.ylabel(\"pc2 (Principal Component2)\")  # 第一主成分に垂直な方向の軸                                                  \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('pca_feature.png')\n",
    "    plt.show()\n",
    "\n",
    "    # training a classifier                                                                                                 \n",
    "    pca = PCA(n_components=2)\n",
    "    train_x = pca.fit_transform(train_x)\n",
    "    \"\"\"\n",
    "    svm = LinearSVC(C=1.0)\n",
    "    svm.fit(train_x, train_y)\n",
    "    joblib.dump(svm, 'model.pkl')\n",
    "\n",
    "    # evaluating the model                                                                                                  \n",
    "    test_x, test_y = data[is_train == False], y[is_train == False]\n",
    "    test_x = pca.transform(test_x)\n",
    "    print(pd.crosstab(test_y, svm.predict(test_x),\n",
    "                      rownames=['Actual'], colnames=['Predicted']))\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "def main():\n",
    "\n",
    "   # x_train, x_test, y_train, y_test, valid_data, valid_label = input_data(\"./shadow_path/shadow_path_and_label_train.txt\",\n",
    "    #                                                                          \"./shadow_path/shadow_path_and_label_test.txt\")\n",
    "\n",
    "  #  old_session = KTF.get_session()\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        session = tf.Session('')\n",
    "        \n",
    "        KTF.set_session(session)\n",
    "        \"\"\"\n",
    "        KTF.set_learning_phase(1)#(0 = test, 1 = train)\n",
    "\n",
    "     #   saver = tf.train.Saver()\n",
    "\n",
    "        model = Sequential()                                                                                                \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape, kernel_initializer=\"he_normal\", bias_initializer=\"zeros\"))                                                                         \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))                                                                    \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Flatten())                                                                                                \n",
    "        model.add(Dense(1512, activation='relu', init='he_uniform'))          # どのようにハイパーパラメータ512を決めるのか→https://stackoverflow.com/questions/36950394/how-to-decide-the-size-of-layers-in-keras-dense-method                                                \n",
    "        #model.add(Dropout(0.5))                                                                                             \n",
    "        model.add(Dense(num_classes, activation='softmax')) # num_classes = 2値分類                                         \n",
    "    \n",
    "                                                                                                                            \n",
    " \n",
    "        \"\"\"\n",
    "        model = load_model('./model/shadow/shadow.h5')\n",
    "        print(model.summary())\n",
    "       \n",
    "\n",
    "        \"\"\"\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,                                                           \n",
    "                      optimizer=\"SGD\",                                                                                      \n",
    "                      metrics=['accuracy'])                                                                                 \n",
    "                                                                                                                            \n",
    "        print(model.summary())                                                                                              \n",
    "                                                                                                                            \n",
    "        # callback function                                                                                                 \n",
    "        tb_cb = keras.callbacks.TensorBoard(log_dir=f_log, histogram_freq=1)                                                \n",
    "        cbks = [tb_cb]                                                                                                      \n",
    "                                                                                                                            \n",
    "        # train                                                                                                             \n",
    "        history = model.fit(x_train, y_train,                                                                               \n",
    "                            batch_size=batch_size,                                                                          \n",
    "                            epochs=epochs,                                                                                  \n",
    "                            verbose=1,       #進行状況の表示モード                                                          \n",
    "                            callbacks=cbks,  # [plot_losses, csv_logger],                                                   \n",
    "                            validation_data=(x_test, y_test))                                                               \n",
    "        score_train = model.evaluate(x_train,y_train, verbose=1, batch_size=batch_size)                                              \n",
    "        score_test = model.evaluate(x_test, y_test, verbose=1, batch_size=batch_size)                                                \n",
    "        print('Train loss: {0}'.format(score_train[0]))                                                                     \n",
    "        print('Train accuracy: {0}'.format(score_train[1]))                                                                 \n",
    "        print('Test loss: {0}'.format(score_test[0]))                                                                       \n",
    "        print('Test accuracy: {0}'.format(score_test[1]))                                                                   \n",
    "\n",
    "        \n",
    "       # saver.save(sess, 'ckpt/model.ckpt',)\n",
    "        model.save('./model/shadow/shadow.h5')\n",
    "\n",
    "        \"\"\"\n",
    "        #テスト画像全ての正誤を取得\n",
    "#        check_accuracy_rate(model)\n",
    "    \n",
    "#        img = image.load_img(\"/home/seimei/brush.jpg\", target_size=(300, 300))\n",
    "\n",
    "    # add for TeonsorBoard                                                                                                                                  \n",
    "    \n",
    "\n",
    "        url =\"/home/seimei/Graduation_Research/shadow_dataset/test_data/shadow_test/image42.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/hare/class_B2/image_0058.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset_valid/hare/hare_D3/image_0028.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/hare/class_B2/image_0058.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/shadow_dataset/test_data/object_shadow_test/image24.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/src/SegNet/SBU-shadow/train/lssd979.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset_valid/hare/hare_D3/image_0028.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/kumori/class_B2/image_0051.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/kumori/class_B7/image_0018.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/kumori/class_B8/image_0045.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/hare/class1-3/class1-3_video1_cropped/image_0011.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/hare/hare_D2/image_0068.jpg\"\n",
    "        #\"/home/seimei/Graduation_Research/dataset/hare/class_B4/image_0030.jpg\"\n",
    "        img = image.img_to_array(img_to_matrix(url))\n",
    "        img=img.astype('float32')\n",
    "        img /= 255.0\n",
    "\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "           # preprocessed_input = load_image(\"/home/seimei/image_0058_brush.jpg\")\n",
    "        \n",
    "\n",
    "        predictions=model.predict(img)#np.expand_dims(img, axis=0))\n",
    "        predicted_class= np.argmax(predictions)\n",
    "        print(predicted_class)\n",
    "        print(predictions)\n",
    "        cam, heatmap = grad_cam(model, img, 1, \"conv2d_6\")\n",
    "        cv2.imwrite(\"gradcam.jpg\", cam)\n",
    "        cv2.imwrite(\"test_heatmap.jpg\", heatmap)\n",
    "        register_gradient()\n",
    "        guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "        saliency_fn = compile_saliency_function(guided_model,'conv2d_6')\n",
    "        saliency = saliency_fn([img, 0])#[np.expand_dims(img, axis=0), 0])\n",
    "        print(saliency)\n",
    "        gradcam = saliency[0] #* heatmap[..., np.newaxis]\n",
    "        #  print(type(gradcam))\n",
    "        cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))\n",
    "        \"\"\"\n",
    "##       ===================================================================中間層の可視化\n",
    "        # modelのlayer_nameを調べる                                                                                                                         \n",
    "        for layer in model.layers:\n",
    "            print(layer.name)\n",
    "\n",
    "        layer_name =\"conv2d_8\"# \"max_pooling2d_1\"                                                                                    \n",
    "        intermediate_layer_model = keras.models.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "\n",
    "        layers = model.layers[10:11]     \n",
    "        \n",
    "        urls = [\"/home/seimei/Graduation_Research/shadow_dataset/test_data/ground_test/image10.jpg\", \n",
    "        \"/home/seimei/Graduation_Research/shadow_dataset/test_data/object_shadow_test/image24.jpg\"]\n",
    "        \n",
    "        width=37\n",
    "        high=37\n",
    "        channel=256\n",
    "        \n",
    "        activations = np.zeros((0,width,high,channel))\n",
    "        for url in urls:\n",
    "            img = image.load_img(url, target_size=(300, 300))\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            # 指定したlayer_nameと一致するレイヤーの出力を取得する                                                                                              \n",
    "            _activations = intermediate_layer_model.predict(img)\n",
    "            _activations = [activation for layer, activation in zip(layers, _activations) if isinstance(layer, Conv2D)]\n",
    "            print(np.shape(_activations))\n",
    "            activations = np.r_[activations, np.reshape(_activations,(-1,width,high,channel))]\n",
    "        print(np.shape(activations))\n",
    "        \"\"\"\n",
    "        \n",
    "##        =================================================================== PCA\n",
    "         \n",
    "        #PCA\n",
    "       # y = keras.utils.to_categorical(np.r_[np.zeros(channel), np.ones(channel)], num_classes)\n",
    "       # handle_image_with_pca(activations, y,channel)\n",
    "\n",
    "        \n",
    "        session.close()\n",
    "    sess.close()\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
